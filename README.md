# Image_Captioning
Image Captioning with inception_v3 and LSTM with attention

В этом проекте я решала задачу получения описания изображения с помощью нейросетей.

Для генерации описания используются две модели:
1) Базовая состоит из предобученной inception_v3, которая выдает векторы изображения, и простой LSTM-модели в качестве декодера(генератора описания). Эта сеть генерирует всего один вариант описания изображения.
2) Вторая модель состоит из предобученной inception_v3, которая выдает векторы изображения, и модели с двумя слоями LSTM и слоем attention в качестве декодера(генератора описания). Эта сеть генерирует несколько вариантов описания.

Все указанные эксперименты описаны в ноутбуке image_captioning_github.ipynb.

Также попробовала обучать обе модели на двух датасетах (coco и flickr30k). Процесс предобработки датасетов, обучения и результаты представлены в файле image_captioning_COCO_plus_Flickr.ipynb.

Папка modules содержит файлы с классами для dataset-а, dataloader-а, моделей и др.

Для тестирования результатов работы создан и запущен на сервере телеграм-бот [@Caption_For_Image_Bot](https://t.me/Caption_For_Image_Bot). Он получает от пользователя изображение и в ответ выдает сгенерированное нейросетью описание этого изображения на английском языке.
В боте работает только первая (базовая) модель.

Мой Телеграм, если возникнут вопросы: [@Ekaterina_Kusakina](https://t.me/Ekaterina_Kusakina)
